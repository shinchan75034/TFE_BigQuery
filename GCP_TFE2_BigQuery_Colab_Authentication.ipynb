{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "environment": {
      "name": "tf2-gpu.2-1.m46",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "GCP_TFE2_BigQuery_Colab_Authentication.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shinchan75034/TFE_BigQuery/blob/master/GCP_TFE2_BigQuery_Colab_Authentication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycEHG8bRdcCG",
        "colab_type": "text"
      },
      "source": [
        "### Reference\n",
        "Had to make a change in creating `one_shot_iterator`. It has to wrap around `tf.compact.v1.data`. <br />\n",
        "This is modified from [here](https://cloud.google.com/blog/products/ai-machine-learning/tensorflow-enterprise-makes-accessing-data-on-google-cloud-faster-and-easier \"TFE and BigQuery\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cbv6JC-72vn",
        "colab_type": "text"
      },
      "source": [
        "### Install TensorFlow IO\n",
        "This is necesary in Colab. In Google Cloud service such as AI notebook or Deep Learning VM, this is installed along as a part of TensorFlow Enterprise distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzhquIqD0ukN",
        "colab_type": "code",
        "outputId": "09e943b8-2d4d-4e83-9b2c-a1416857dcb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        " !pip install tensorflow-io"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-io\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/d5/fed76bdd291d3ada5b159e47638fb639dd01bfb3361a58b00fb61f60682f/tensorflow_io-0.13.0-cp36-cp36m-manylinux2010_x86_64.whl (20.9MB)\n",
            "\u001b[K     |████████████████████████████████| 20.9MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-io) (2.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.3.0,>=2.2.0->tensorflow-io) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.3.0,>=2.2.0->tensorflow-io) (2.2.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.3.0,>=2.2.0->tensorflow-io) (1.18.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.3.0,>=2.2.0->tensorflow-io) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.3.0,>=2.2.0->tensorflow-io) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.3.0,>=2.2.0->tensorflow-io) (3.2.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.3.0,>=2.2.0->tensorflow-io) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.3.0,>=2.2.0->tensorflow-io) (3.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.3.0,>=2.2.0->tensorflow-io) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.3.0,>=2.2.0->tensorflow-io) (2.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.3.0,>=2.2.0->tensorflow-io) (1.29.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.3.0,>=2.2.0->tensorflow-io) (1.6.3)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.3.0,>=2.2.0->tensorflow-io) (0.34.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.3.0,>=2.2.0->tensorflow-io) (2.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.3.0,>=2.2.0->tensorflow-io) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.3.0,>=2.2.0->tensorflow-io) (1.12.1)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.3.0,>=2.2.0->tensorflow-io) (1.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (1.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (46.3.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (1.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (2.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow<2.3.0,>=2.2.0->tensorflow-io) (3.1.0)\n",
            "Installing collected packages: tensorflow-io\n",
            "Successfully installed tensorflow-io-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OuWlO1OiqlR",
        "colab_type": "code",
        "outputId": "9435b942-8dd5-424d-e172-cd88655d9d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!ls -lrt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4\n",
            "drwxr-xr-x 1 root root 4096 May 13 16:29 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ozAYxf61OO4",
        "colab_type": "code",
        "outputId": "86ae15fe-acae-4fe2-a09b-eac905d6d20c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authenticated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF_TdwrR2DYG",
        "colab_type": "text"
      },
      "source": [
        "Set environmental variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLma8vp52CcK",
        "colab_type": "code",
        "outputId": "871c3e5d-de17-4b9f-98ab-0e31c85cd602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "PROJECT_ID = \"project1-190517\" #@param {type:\"string\"}\n",
        "! gcloud config set project $PROJECT_ID\n",
        "%env GCLOUD_PROJECT=$PROJECT_ID"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "env: GCLOUD_PROJECT=project1-190517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGlsZdVph4QJ",
        "colab_type": "code",
        "outputId": "8f469b5e-42a1-4a2d-9373-464d5362203f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!ls -lrt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 May 13 16:29 sample_data\n",
            "-rw-r--r-- 1 root root 2664 May 19 21:31 adc.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec82ITjL5VEM",
        "colab_type": "text"
      },
      "source": [
        "### Authentication \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-r7dPMkHDWi",
        "colab_type": "text"
      },
      "source": [
        "Colab notebook requires extra authentication steps below. You don't need to do this if you are running in Google Cloud service environment such as a AI notebook, because in there, you are authenticated in your Google Cloud tenant. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9XPvwZQHNZ8",
        "colab_type": "text"
      },
      "source": [
        "According to instruction [here](https://cloud.google.com/iam/docs/creating-managing-service-account-keys#iam-service-account-keys-create-console  \"Google Cloud IAM & Admins\"), go Google Cloud IAM & Admins tab to choose a service account email, create a key and downlowd the key in JSON format at your local computer, then in the cell below, upload it to your Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqd5coI3kPUh",
        "colab_type": "code",
        "outputId": "f0d64bd6-b4ed-4f37-8dc0-78dbd22c8ad4",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c45c837a-7ac3-48f0-8814-b92b762cbbe2\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c45c837a-7ac3-48f0-8814-b92b762cbbe2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving project1-190517-858599adc951.json to project1-190517-858599adc951.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgejDf4Ekbsf",
        "colab_type": "code",
        "outputId": "8f71e8da-10a8-4493-a226-d5607255c95f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!rm service_account.json\n",
        "!ln -s project1-190517-858599adc951.json service_account.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'service_account.json': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmubVuWTlbg7",
        "colab_type": "code",
        "outputId": "43125e7a-b202-49f6-eeb2-59635577d49b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls -lrt ./service_account.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lrwxrwxrwx 1 root root 33 May 19 21:31 ./service_account.json -> project1-190517-858599adc951.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvK8HTtjsovc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat ./service_account.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtgdBgQ0lIQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.cloud import bigquery\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "# TODO(developer): Set key_path to the path to the service account key\n",
        "#                  file.\n",
        "key_path = \"./service_account.json\"\n",
        "\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "    key_path,\n",
        "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
        ")\n",
        "\n",
        "client = bigquery.Client(\n",
        "    credentials=credentials,\n",
        "    project=credentials.project_id,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfyf_KlNsj1o",
        "colab_type": "code",
        "outputId": "81c65b68-98ce-48ca-995c-c2bf0ef9e4f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "client"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.cloud.bigquery.client.Client at 0x7fead431e6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9h_9Aul4yTU",
        "colab_type": "text"
      },
      "source": [
        "Now we have completed all the client authentication steps necessary for this Colab to use BigQuery API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_4RrvD2_0Z8",
        "colab_type": "text"
      },
      "source": [
        "### Run BigQuery API without using TensorFlow IO\n",
        "The first way we can try is calling BigQuery API directly from Python. This will give us direct access to the data, execute the query, and receive the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cL5aS0EjaBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_id =\"project1-190517\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs0y-bz-4qQ5",
        "colab_type": "code",
        "outputId": "862fd3e4-aa0d-4ec5-d37d-169a8cd779e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "sample_count = 2000\n",
        "row_count = client.query('''\n",
        "  SELECT \n",
        "    COUNT(*) as total\n",
        "  FROM `bigquery-public-data.samples.gsod`''').to_dataframe().total[0]\n",
        "\n",
        "df = client.query('''\n",
        "  SELECT\n",
        "    *\n",
        "  FROM\n",
        "    `bigquery-public-data.samples.gsod`\n",
        "  WHERE RAND() < %d/%d\n",
        "''' % (sample_count, row_count)).to_dataframe()\n",
        "\n",
        "print('Full dataset has %d rows' % row_count)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Full dataset has 114420316 rows\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzGgVec84u6r",
        "colab_type": "code",
        "outputId": "c413b222-9e99-4d82-ebfe-6d147d62ab41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>station_number</th>\n",
              "      <th>wban_number</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>mean_temp</th>\n",
              "      <th>num_mean_temp_samples</th>\n",
              "      <th>mean_dew_point</th>\n",
              "      <th>num_mean_dew_point_samples</th>\n",
              "      <th>mean_sealevel_pressure</th>\n",
              "      <th>num_mean_sealevel_pressure_samples</th>\n",
              "      <th>mean_station_pressure</th>\n",
              "      <th>num_mean_station_pressure_samples</th>\n",
              "      <th>mean_visibility</th>\n",
              "      <th>num_mean_visibility_samples</th>\n",
              "      <th>mean_wind_speed</th>\n",
              "      <th>num_mean_wind_speed_samples</th>\n",
              "      <th>max_sustained_wind_speed</th>\n",
              "      <th>max_gust_wind_speed</th>\n",
              "      <th>max_temperature</th>\n",
              "      <th>total_precipitation</th>\n",
              "      <th>snow_depth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1946.000000</td>\n",
              "      <td>1946.000000</td>\n",
              "      <td>1946.000000</td>\n",
              "      <td>1946.000000</td>\n",
              "      <td>1946.000000</td>\n",
              "      <td>1946.000000</td>\n",
              "      <td>1946.000000</td>\n",
              "      <td>1861.000000</td>\n",
              "      <td>1861.000000</td>\n",
              "      <td>1488.000000</td>\n",
              "      <td>1488.000000</td>\n",
              "      <td>717.000000</td>\n",
              "      <td>717.000000</td>\n",
              "      <td>1730.000000</td>\n",
              "      <td>1730.000000</td>\n",
              "      <td>1920.000000</td>\n",
              "      <td>1920.000000</td>\n",
              "      <td>1890.000000</td>\n",
              "      <td>317.000000</td>\n",
              "      <td>1945.000000</td>\n",
              "      <td>1786.000000</td>\n",
              "      <td>101.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>500668.700925</td>\n",
              "      <td>89078.760021</td>\n",
              "      <td>1987.696814</td>\n",
              "      <td>6.594553</td>\n",
              "      <td>15.810894</td>\n",
              "      <td>51.513309</td>\n",
              "      <td>12.966598</td>\n",
              "      <td>40.438098</td>\n",
              "      <td>12.897367</td>\n",
              "      <td>1014.314717</td>\n",
              "      <td>11.594086</td>\n",
              "      <td>960.870013</td>\n",
              "      <td>12.152022</td>\n",
              "      <td>12.358786</td>\n",
              "      <td>12.635260</td>\n",
              "      <td>7.128958</td>\n",
              "      <td>12.895833</td>\n",
              "      <td>12.643862</td>\n",
              "      <td>25.454574</td>\n",
              "      <td>43.028946</td>\n",
              "      <td>0.066529</td>\n",
              "      <td>9.099010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>299115.051121</td>\n",
              "      <td>27732.276606</td>\n",
              "      <td>15.581828</td>\n",
              "      <td>3.451992</td>\n",
              "      <td>8.834799</td>\n",
              "      <td>24.246043</td>\n",
              "      <td>7.951486</td>\n",
              "      <td>22.701581</td>\n",
              "      <td>7.968196</td>\n",
              "      <td>9.712622</td>\n",
              "      <td>7.622606</td>\n",
              "      <td>79.920111</td>\n",
              "      <td>7.886807</td>\n",
              "      <td>8.848615</td>\n",
              "      <td>7.875141</td>\n",
              "      <td>5.140760</td>\n",
              "      <td>7.913984</td>\n",
              "      <td>7.076316</td>\n",
              "      <td>8.712668</td>\n",
              "      <td>24.212716</td>\n",
              "      <td>0.298507</td>\n",
              "      <td>9.729198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>10010.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>1938.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-90.400002</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>-97.400002</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>950.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>603.400024</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.900000</td>\n",
              "      <td>7.800000</td>\n",
              "      <td>-105.199997</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>238152.500000</td>\n",
              "      <td>99999.000000</td>\n",
              "      <td>1978.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>38.299999</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>28.600000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1008.799988</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>949.500000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.600000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.700000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.800000</td>\n",
              "      <td>19.400000</td>\n",
              "      <td>31.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>529230.000000</td>\n",
              "      <td>99999.000000</td>\n",
              "      <td>1989.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>53.900002</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>43.099998</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1014.099976</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>991.900024</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.900000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.100000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>23.299999</td>\n",
              "      <td>45.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>725107.750000</td>\n",
              "      <td>99999.000000</td>\n",
              "      <td>2001.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>69.800003</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>55.799999</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>1019.799988</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1009.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>15.075000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>9.200000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>15.900000</td>\n",
              "      <td>29.900000</td>\n",
              "      <td>60.099998</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>14.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>999999.000000</td>\n",
              "      <td>99999.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>98.400002</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>81.400002</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>1051.800049</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>1037.800049</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>91.800003</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>62.200001</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>69.900002</td>\n",
              "      <td>62.200001</td>\n",
              "      <td>87.800003</td>\n",
              "      <td>7.240000</td>\n",
              "      <td>63.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       station_number   wban_number  ...  total_precipitation  snow_depth\n",
              "count     1946.000000   1946.000000  ...          1786.000000  101.000000\n",
              "mean    500668.700925  89078.760021  ...             0.066529    9.099010\n",
              "std     299115.051121  27732.276606  ...             0.298507    9.729198\n",
              "min      10010.000000    137.000000  ...             0.000000    0.400000\n",
              "25%     238152.500000  99999.000000  ...             0.000000    2.000000\n",
              "50%     529230.000000  99999.000000  ...             0.000000    6.300000\n",
              "75%     725107.750000  99999.000000  ...             0.010000   14.200000\n",
              "max     999999.000000  99999.000000  ...             7.240000   63.000000\n",
              "\n",
              "[8 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vID3ze4m4uxK",
        "colab_type": "code",
        "outputId": "9b1038b8-c591-4e85-cc83-65d6f68e03bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "sample_count = 2000\n",
        "df = pd.io.gbq.read_gbq('''\n",
        "  SELECT name, SUM(number) as count\n",
        "  FROM `bigquery-public-data.usa_names.usa_1910_2013`\n",
        "  WHERE state = 'TX'\n",
        "  GROUP BY name\n",
        "  ORDER BY count DESC\n",
        "  LIMIT 100\n",
        "''', project_id=project_id, dialect='standard')\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>James</td>\n",
              "      <td>272793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>John</td>\n",
              "      <td>235139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Michael</td>\n",
              "      <td>225320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Robert</td>\n",
              "      <td>220399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>David</td>\n",
              "      <td>219028</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      name   count\n",
              "0    James  272793\n",
              "1     John  235139\n",
              "2  Michael  225320\n",
              "3   Robert  220399\n",
              "4    David  219028"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS2qb80-CcaB",
        "colab_type": "text"
      },
      "source": [
        "### Run BigQuery API with TensorFlow IO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjHT8NwwC2Zn",
        "colab_type": "text"
      },
      "source": [
        "For TensorFlow consumption of BigQuery Data, it is better if we would use TensorFlow IO to invoke the BigQuery API. This is because TensorFlow IO will provide us with a dataset object that represents the query results, rather than the entire results as in the previous way. Dataset object is the means to streaming data to model during training. This is necessary when data size gets very big."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfHXhK1EdcCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow_io.bigquery import BigQueryClient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAtc16O9dcCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PROJECT_ID = \"project1-190517\" # This is from what you created in your Google Cloud Account. \n",
        "DATASET_GCP_PROJECT_ID = \"bigquery-public-data\"\n",
        "DATASET_ID = \"samples\"\n",
        "TABLE_ID = \"wikipedia\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzzNNQFFD3dp",
        "colab_type": "text"
      },
      "source": [
        "Lets wrap around the client and session call in a function. Notice that a tradeoff is that we must know the schema of table beforehand. It won't work as an ad hoc query like previous way of using BigQuery API call without using TensorFlow IO. Also, we have to create a session to read the data. These are some obvious complications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQo5gnPX1rAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use this function to create a BigQuery client with read session.\n",
        "def run_bqsession(num_iterations):\n",
        "  batch_size = 2048\n",
        "  client = BigQueryClient()\n",
        "  read_session = client.read_session(\n",
        "      \"projects/\" + PROJECT_ID,\n",
        "      DATASET_GCP_PROJECT_ID, TABLE_ID, DATASET_ID,\n",
        "      [\"title\",\n",
        "       \"id\",\n",
        "       \"num_characters\",\n",
        "       \"language\",\n",
        "       \"timestamp\",\n",
        "       \"wp_namespace\",\n",
        "       \"contributor_username\"],\n",
        "      [tf.string,\n",
        "       tf.int64,\n",
        "       tf.int64,\n",
        "       tf.string,\n",
        "       tf.int64,\n",
        "       tf.int64,\n",
        "       tf.string],\n",
        "      requested_streams=10\n",
        "  )\n",
        "\n",
        "  dataset = read_session.parallel_read_rows(sloppy=True).batch(batch_size)\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EceBYBNB1q8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batcheddataset = run_bqsession(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ehgd_4t1zO4",
        "colab_type": "code",
        "outputId": "3834092d-f4b6-4301-896c-5d58bba1a97d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(batcheddataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.BatchDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_kbplYlE0jK",
        "colab_type": "text"
      },
      "source": [
        "### Examine dataset returned by TensorFlow IO Ops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pBcV-K4FBkp",
        "colab_type": "text"
      },
      "source": [
        "Dataset structure is inherently a Python iterator. We can output the actual content of the data using `next()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE69PAM-1zKz",
        "colab_type": "code",
        "outputId": "3579357e-c26f-40c9-f6f2-dfab75ea8060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "next(iter(batcheddataset))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('contributor_username',\n",
              "              <tf.Tensor: shape=(2048,), dtype=string, numpy=array([b'', b'MSGJ', b'', ..., b'', b'', b''], dtype=object)>),\n",
              "             ('id',\n",
              "              <tf.Tensor: shape=(2048,), dtype=int64, numpy=array([ 1462053, 15851098,  6459333, ..., 21315055,  1533342, 10607447])>),\n",
              "             ('language',\n",
              "              <tf.Tensor: shape=(2048,), dtype=string, numpy=array([b'', b'', b'', ..., b'', b'', b''], dtype=object)>),\n",
              "             ('num_characters',\n",
              "              <tf.Tensor: shape=(2048,), dtype=int64, numpy=array([20009, 81301, 30391, ..., 16407, 11407,  2163])>),\n",
              "             ('timestamp', <tf.Tensor: shape=(2048,), dtype=int64, numpy=\n",
              "              array([1173977859, 1252849786, 1167244494, ..., 1175541864, 1262753759,\n",
              "                     1184276488])>),\n",
              "             ('title', <tf.Tensor: shape=(2048,), dtype=string, numpy=\n",
              "              array([b'Strait of Messina Bridge', b'Template talk:WPBannerMeta',\n",
              "                     b'2007 in music', ..., b'Wirral Grammar School for Boys',\n",
              "                     b'TED (conference)', b'URL Subscription Architecture'],\n",
              "                    dtype=object)>),\n",
              "             ('wp_namespace',\n",
              "              <tf.Tensor: shape=(2048,), dtype=int64, numpy=array([ 0, 11,  0, ...,  0,  0,  0])>)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9RoQRmpFSJk",
        "colab_type": "text"
      },
      "source": [
        "Lets not wrap it around a function. Lets just use the code as-is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixy7LxgZdcCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 2048\n",
        "client = BigQueryClient()\n",
        "read_session = client.read_session(\n",
        "    \"projects/\" + PROJECT_ID,\n",
        "    DATASET_GCP_PROJECT_ID, TABLE_ID, DATASET_ID,\n",
        "    [\"title\",\n",
        "     \"id\",\n",
        "     \"num_characters\",\n",
        "     \"language\",\n",
        "     \"timestamp\",\n",
        "     \"wp_namespace\",\n",
        "     \"contributor_username\"],\n",
        "    [tf.string,\n",
        "     tf.int64,\n",
        "     tf.int64,\n",
        "     tf.string,\n",
        "     tf.int64,\n",
        "     tf.int64,\n",
        "     tf.string],\n",
        "      requested_streams=10\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZQtpusGdcCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = read_session.parallel_read_rows(sloppy=True).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8vT8RqidcC4",
        "colab_type": "code",
        "outputId": "f14ab11c-10d5-4a06-8afc-088e3b3ae877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.BatchDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6JzicsBdcC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "itr = tf.compat.v1.data.make_one_shot_iterator(\n",
        "    dataset\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAWcucEjGOhC",
        "colab_type": "text"
      },
      "source": [
        "Lets try to get a feel for read speed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNcgopstdcDI",
        "colab_type": "code",
        "outputId": "e0cbb4ef-504d-4190-f68e-3856255761f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "n = 0\n",
        "mini_batch = 100\n",
        "num_iterations = 10000\n",
        "for i in range(num_iterations // mini_batch):\n",
        "    local_start = time.time()\n",
        "    start_n = n\n",
        "    for j in range(mini_batch):\n",
        "        n += batch_size\n",
        "        batch = itr.get_next()    \n",
        "    local_end = time.time()\n",
        "    print('Processed %d entries in %f seconds. [%f] examples/s' % (n - start_n, local_end - local_start, (mini_batch * batch_size) / (local_end - local_start)))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processed 204800 entries in 6.675380 seconds. [30679.900312] examples/s\n",
            "Processed 204800 entries in 0.803941 seconds. [254745.134064] examples/s\n",
            "Processed 204800 entries in 0.786988 seconds. [260232.678021] examples/s\n",
            "Processed 204800 entries in 0.794928 seconds. [257633.371784] examples/s\n",
            "Processed 204800 entries in 0.785177 seconds. [260832.751855] examples/s\n",
            "Processed 204800 entries in 0.800716 seconds. [255770.957061] examples/s\n",
            "Processed 204800 entries in 0.794140 seconds. [257889.004568] examples/s\n",
            "Processed 204800 entries in 0.806647 seconds. [253890.617887] examples/s\n",
            "Processed 204800 entries in 0.789359 seconds. [259450.992445] examples/s\n",
            "Processed 204800 entries in 0.804452 seconds. [254583.187009] examples/s\n",
            "Processed 204800 entries in 0.814778 seconds. [251356.710134] examples/s\n",
            "Processed 204800 entries in 0.854899 seconds. [239560.549236] examples/s\n",
            "Processed 204800 entries in 0.813641 seconds. [251708.188344] examples/s\n",
            "Processed 204800 entries in 0.856135 seconds. [239214.640159] examples/s\n",
            "Processed 204800 entries in 0.839786 seconds. [243871.706947] examples/s\n",
            "Processed 204800 entries in 0.833282 seconds. [245775.071237] examples/s\n",
            "Processed 204800 entries in 0.823991 seconds. [248546.385851] examples/s\n",
            "Processed 204800 entries in 0.841133 seconds. [243481.080100] examples/s\n",
            "Processed 204800 entries in 0.835471 seconds. [245131.144506] examples/s\n",
            "Processed 204800 entries in 0.844155 seconds. [242609.452351] examples/s\n",
            "Processed 204800 entries in 0.828717 seconds. [247128.926676] examples/s\n",
            "Processed 204800 entries in 0.828581 seconds. [247169.672539] examples/s\n",
            "Processed 204800 entries in 0.821824 seconds. [249201.753187] examples/s\n",
            "Processed 204800 entries in 0.836149 seconds. [244932.568666] examples/s\n",
            "Processed 204800 entries in 0.818356 seconds. [250257.968461] examples/s\n",
            "Processed 204800 entries in 0.829706 seconds. [246834.292814] examples/s\n",
            "Processed 204800 entries in 0.864059 seconds. [237020.924830] examples/s\n",
            "Processed 204800 entries in 0.839451 seconds. [243968.953280] examples/s\n",
            "Processed 204800 entries in 0.821502 seconds. [249299.462943] examples/s\n",
            "Processed 204800 entries in 0.845012 seconds. [242363.436531] examples/s\n",
            "Processed 204800 entries in 0.842404 seconds. [243113.718709] examples/s\n",
            "Processed 204800 entries in 0.842442 seconds. [243102.710177] examples/s\n",
            "Processed 204800 entries in 0.835315 seconds. [245176.832411] examples/s\n",
            "Processed 204800 entries in 0.842598 seconds. [243057.791943] examples/s\n",
            "Processed 204800 entries in 2.040867 seconds. [100349.492162] examples/s\n",
            "Processed 204800 entries in 0.832520 seconds. [246000.234604] examples/s\n",
            "Processed 204800 entries in 0.825804 seconds. [248000.809315] examples/s\n",
            "Processed 204800 entries in 0.833319 seconds. [245764.312576] examples/s\n",
            "Processed 204800 entries in 0.849693 seconds. [241028.213199] examples/s\n",
            "Processed 204800 entries in 0.852736 seconds. [240167.984441] examples/s\n",
            "Processed 204800 entries in 0.860065 seconds. [238121.409911] examples/s\n",
            "Processed 204800 entries in 0.820760 seconds. [249524.682130] examples/s\n",
            "Processed 204800 entries in 0.827463 seconds. [247503.540192] examples/s\n",
            "Processed 204800 entries in 0.821594 seconds. [249271.610388] examples/s\n",
            "Processed 204800 entries in 0.864600 seconds. [236872.492469] examples/s\n",
            "Processed 204800 entries in 0.882045 seconds. [232187.817642] examples/s\n",
            "Processed 204800 entries in 0.838722 seconds. [244180.891719] examples/s\n",
            "Processed 204800 entries in 0.833492 seconds. [245713.344796] examples/s\n",
            "Processed 204800 entries in 0.853113 seconds. [240061.868579] examples/s\n",
            "Processed 204800 entries in 0.809244 seconds. [253075.735980] examples/s\n",
            "Processed 204800 entries in 0.804864 seconds. [254452.948418] examples/s\n",
            "Processed 204800 entries in 0.820528 seconds. [249595.445764] examples/s\n",
            "Processed 204800 entries in 0.810512 seconds. [252679.767050] examples/s\n",
            "Processed 204800 entries in 0.814435 seconds. [251462.668838] examples/s\n",
            "Processed 204800 entries in 0.813934 seconds. [251617.425884] examples/s\n",
            "Processed 204800 entries in 0.826155 seconds. [247895.386542] examples/s\n",
            "Processed 204800 entries in 0.847976 seconds. [241516.278068] examples/s\n",
            "Processed 204800 entries in 0.814252 seconds. [251519.143036] examples/s\n",
            "Processed 204800 entries in 0.823385 seconds. [248729.474725] examples/s\n",
            "Processed 204800 entries in 0.816248 seconds. [250904.008828] examples/s\n",
            "Processed 204800 entries in 0.809717 seconds. [252927.968040] examples/s\n",
            "Processed 204800 entries in 0.820379 seconds. [249640.709125] examples/s\n",
            "Processed 204800 entries in 0.835423 seconds. [245145.415774] examples/s\n",
            "Processed 204800 entries in 0.871834 seconds. [234907.028942] examples/s\n",
            "Processed 204800 entries in 0.834446 seconds. [245432.382635] examples/s\n",
            "Processed 204800 entries in 2.096060 seconds. [97707.124951] examples/s\n",
            "Processed 204800 entries in 0.838638 seconds. [244205.535406] examples/s\n",
            "Processed 204800 entries in 0.822026 seconds. [249140.389271] examples/s\n",
            "Processed 204800 entries in 0.823126 seconds. [248807.715125] examples/s\n",
            "Processed 204800 entries in 0.875512 seconds. [233920.169491] examples/s\n",
            "Processed 204800 entries in 0.867539 seconds. [236070.098018] examples/s\n",
            "Processed 204800 entries in 0.819524 seconds. [249901.074263] examples/s\n",
            "Processed 204800 entries in 0.820302 seconds. [249664.000037] examples/s\n",
            "Processed 204800 entries in 0.824307 seconds. [248451.133773] examples/s\n",
            "Processed 204800 entries in 0.828998 seconds. [247045.272671] examples/s\n",
            "Processed 204800 entries in 0.839716 seconds. [243891.925583] examples/s\n",
            "Processed 204800 entries in 0.824055 seconds. [248527.113878] examples/s\n",
            "Processed 204800 entries in 0.827764 seconds. [247413.575015] examples/s\n",
            "Processed 204800 entries in 0.832648 seconds. [245962.197470] examples/s\n",
            "Processed 204800 entries in 0.837095 seconds. [244655.687704] examples/s\n",
            "Processed 204800 entries in 0.828211 seconds. [247279.888766] examples/s\n",
            "Processed 204800 entries in 0.845677 seconds. [242172.799700] examples/s\n",
            "Processed 204800 entries in 0.826378 seconds. [247828.443478] examples/s\n",
            "Processed 204800 entries in 0.809748 seconds. [252918.063404] examples/s\n",
            "Processed 204800 entries in 0.813272 seconds. [251822.342587] examples/s\n",
            "Processed 204800 entries in 0.846462 seconds. [241948.247242] examples/s\n",
            "Processed 204800 entries in 0.845743 seconds. [242153.889038] examples/s\n",
            "Processed 204800 entries in 0.815437 seconds. [251153.651711] examples/s\n",
            "Processed 204800 entries in 0.879236 seconds. [232929.439251] examples/s\n",
            "Processed 204800 entries in 0.812441 seconds. [252079.809017] examples/s\n",
            "Processed 204800 entries in 0.818540 seconds. [250201.621866] examples/s\n",
            "Processed 204800 entries in 0.816189 seconds. [250922.405146] examples/s\n",
            "Processed 204800 entries in 0.827934 seconds. [247362.704504] examples/s\n",
            "Processed 204800 entries in 0.885308 seconds. [231331.851218] examples/s\n",
            "Processed 204800 entries in 0.827147 seconds. [247598.138301] examples/s\n",
            "Processed 204800 entries in 0.851402 seconds. [240544.541880] examples/s\n",
            "Processed 204800 entries in 0.835503 seconds. [245121.771145] examples/s\n",
            "Processed 204800 entries in 1.992575 seconds. [102781.555608] examples/s\n",
            "Processed 204800 entries in 0.787034 seconds. [260217.620896] examples/s\n",
            "Processed 204800 entries in 0.838240 seconds. [244321.531632] examples/s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSQhGrncdcDO",
        "colab_type": "text"
      },
      "source": [
        "Lets read another dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gcIkBl6dcDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_GCP_PROJECT_ID = 'project1-190517'\n",
        "TABLE_ID = 'confirmed_cases'\n",
        "DATASET_ID = 'covid19_usafacts'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd8S_L5XdcDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "read_session2 = client.read_session(\n",
        "    \"projects/\" + PROJECT_ID,\n",
        "    DATASET_GCP_PROJECT_ID, TABLE_ID, DATASET_ID,\n",
        "    [\"county_fips_code\",\n",
        "     \"county_name\",\n",
        "     \"state\",\n",
        "     \"state_fips_code\",\n",
        "     \"_1_22_20\"\n",
        "     \n",
        "     ],\n",
        "    [tf.string,\n",
        "     tf.string,\n",
        "     tf.string,\n",
        "     tf.string,\n",
        "     tf.int64\n",
        "     \n",
        "     \n",
        "     ],\n",
        "      requested_streams=10\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XoLZNyGdcDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset2 = read_session2.parallel_read_rows(sloppy=True).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYfet2lRdcDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "itr2 = tf.compat.v1.data.make_one_shot_iterator(dataset2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d8JNpGvdcDm",
        "colab_type": "code",
        "outputId": "12edd8fc-6009-47b0-a6b1-0dfa01421193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "next(itr2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('_1_22_20',\n",
              "              <tf.Tensor: shape=(2048,), dtype=int64, numpy=array([0, 0, 0, ..., 0, 0, 0])>),\n",
              "             ('county_fips_code',\n",
              "              <tf.Tensor: shape=(2048,), dtype=string, numpy=\n",
              "              array([b'01073', b'06001', b'06013', ..., b'28003', b'48277', b'54081'],\n",
              "                    dtype=object)>),\n",
              "             ('county_name', <tf.Tensor: shape=(2048,), dtype=string, numpy=\n",
              "              array([b'Jefferson County', b'Alameda County', b'Contra Costa County',\n",
              "                     ..., b'Alcorn County', b'Lamar County', b'Raleigh County'],\n",
              "                    dtype=object)>),\n",
              "             ('state',\n",
              "              <tf.Tensor: shape=(2048,), dtype=string, numpy=array([b'AL', b'CA', b'CA', ..., b'MS', b'TX', b'WV'], dtype=object)>),\n",
              "             ('state_fips_code',\n",
              "              <tf.Tensor: shape=(2048,), dtype=string, numpy=array([b'01', b'06', b'06', ..., b'28', b'48', b'54'], dtype=object)>)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqMxN0oSdcDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}